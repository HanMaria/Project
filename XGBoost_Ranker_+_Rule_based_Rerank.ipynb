{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanMaria/Project/blob/main/XGBoost_Ranker_%2B_Rule_based_Rerank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AeroClub RecSys 2025 - XGBoost Ranking Baseline**"
      ],
      "metadata": {
        "id": "8F4J9IVqWfJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Library**"
      ],
      "metadata": {
        "id": "6MbkOPTn8Hot"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4729nMAh8AzX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U xgboost\n",
        "!pip install -U polars"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import zipfile\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "MSb-lwYe9DTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "h5Yutpzi9DWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c aeroclub-recsys-2025"
      ],
      "metadata": {
        "id": "BSNZus049DZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/aeroclub-recsys-2025.zip"
      ],
      "metadata": {
        "id": "L5QRLStx9Dc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pl.read_parquet(\"/content/train.parquet\").drop('__index_level_0__')\n",
        "test = pl.read_parquet(\"/content/test.parquet\").drop('__index_level_0__').with_columns(pl.lit(0, dtype=pl.Int64).alias('selected'))\n",
        "\n",
        "data_raw = pl.concat([train, test])"
      ],
      "metadata": {
        "id": "34N5Ou8a_UXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_raw.head()"
      ],
      "metadata": {
        "id": "vXS_afQvBQcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation Metric**"
      ],
      "metadata": {
        "id": "o8Bt8FtxBNkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def  hitrate_at_3(y_true, y_pred, groups):\n",
        "  df = pl.DataFrame({\n",
        "      'group': groups,\n",
        "      'pred': y_pred,\n",
        "      'true': y_true\n",
        "  })\n",
        "\n",
        "  return (\n",
        "      df.filter(pl.col(\"group\").count().over(\"group\") > 10)\n",
        "      .sort([\"group\", \"pred\"], descending=[False, True])\n",
        "      .group_by(\"group\", maintain_order=True)\n",
        "      .head(3)\n",
        "      .group_by(\"group\")\n",
        "      .agg(pl.col(\"true\").max())\n",
        "      .select(pl.col(\"true\").mean())\n",
        "      .item()\n",
        "  )"
      ],
      "metadata": {
        "id": "k0TA0AfY_Ukm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Engineering**"
      ],
      "metadata": {
        "id": "AHxdiEt5C3Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data_raw.clone()\n",
        "\n",
        "# More efficient duration to minute converter\n",
        "def dur_to_min(col):\n",
        "  # Extract days and time parts in one pass\n",
        "  days = col.str.extract(r\"^(\\d+)\\.\", 1).cast(pl.Int64).fill_null(0)*1140\n",
        "  time_str = pl.when(col.str.contains(r\"^(\\d+)\\.\")).then(col.replace(r\"^(\\d+)\\.\", \"\")).otherwise(col)\n",
        "  hours = time_str.str.extract(r\"^(\\d+)\\.\", 1).cast(pl.Int64).fill_null(0)*60\n",
        "  minutes = time_str.str.extract(r\"\\.(\\d+)\", 1).cast(pl.Int64).fill_null(0)\n",
        "  return (days + hours + minutes).fill_null(0)\n",
        "\n",
        "# Process duration columns\n",
        "dur_cols = [\"legs0_duration\", \"legs1_duration\"] + [\"legs{l}_segments{s}_duration\" for l in (0, 1) for s in (0, 1)]\n",
        "dur_exprs = [dur_to_min(pl.col(c)).alias(c) for c in dur_cols if c in df.columns]\n",
        "\n",
        "# Apply duration transformation first\n",
        "if dur_exprs:\n",
        "  df = df.with_columns(dur_exprs)\n",
        "\n",
        "# Precompute marketing carrier columns check\n",
        "mc_cols = [f\"legs{l}_segments{s}_mmarketingCarrier_code\" for l in (0, 1) for s in (0, 1)]\n",
        "mc_exists = [col for col in mc_cols if col in df.columns]\n",
        "\n",
        "# Combine all intial transformation\n",
        "df = df.with_columns([\n",
        "    # Price features\n",
        "    (pl.col(\"totalPrice\") / (pl.col(\"taxes\") + 1)).alias(\"price_per_tax\"),\n",
        "    (pl.col(\"taxes\") / (pl.col(\"totalPrice\") + 1)).alias(\"tax_rate\"),\n",
        "    pl.col(\"totalPrice\").log1p().alias('log_price'),\n",
        "\n",
        "    # Duration features\n",
        "    (pl.col(\"legs0_duration\").fill_null(0) + pl.col(\"legs1_duration\").fill_null(0)).alias(\"total_duration\"),\n",
        "    pl.when(pl.col(\"legs1_duration\").fill_null(0) > 0)\n",
        "    .then(pl.col(\"legs0_duration\") / (pl.col(\"legs1_duration\") + 1))\n",
        "    .otherwise(1.0).alias(\"duration_ratio\"),\n",
        "\n",
        "    # Trip type\n",
        "    (pl.col(\"legs1_duration\").is_null() | (pl.col(\"legs1_duration\") == 0)\n",
        "    | pl.col(\"legs1_segments0_departureFrom_airport_iata\").is_null()).cast(pl.Int32).alias(\"is_one_way\"),\n",
        "\n",
        "    # Total segments count\n",
        "    (pl.sum_horizontal(pl.col(col).is_not_null().cast(pl.UInt8) for col in mc_exists)\n",
        "    if mc_exists else pl.lit(0)).alias(\"l0_seg\"),\n",
        "\n",
        "    # FF features\n",
        "    (pl.col(\"frequentFlyer\").fill_null(\"\").str.count_matches(\"/\") +\n",
        "     (pl.col('frequentFlyer').fill_null(\"\") != \"\").cast(pl.Int32)).alias(\"n_ff_programs\"),\n",
        "\n",
        "    # Binary features\n",
        "    pl.col(\"corporateTariffCode\").is_not_null().cast(pl.Int32).alias(\"has_corporate_tariff\"),\n",
        "    (pl.col('pricingInfo_isAccessTP') == 1).cast(pl.Int32).alias(\"has_access_tp\"),\n",
        "\n",
        "    # Baggage and fees\n",
        "    (pl.col(\"legs0_segments0_baggageAllowance_quantity\").fill_null(0)\n",
        "    + pl.col(\"legs1_segments0_baggageAllowance_quantity\").fill_null(0))\n",
        "    .alias('total_baggage'),\n",
        "\n",
        "    (pl.col(\"miniRules0_monetaryAmount\").fill_null(0) + pl.col(\"miniRules1_monetaryAmount\").fill_null(0))\n",
        "    .alias('total_fees'),\n",
        "\n",
        "    (\n",
        "        (pl.col(\"miniRules0_monetaryAmount\") == 0)\n",
        "        & (pl.col(\"miniRules0_statusInfos\") == 1)\n",
        "    )\n",
        "    .cast(pl.Int8)\n",
        "    .alias('free_cancel'),\n",
        "\n",
        "    (\n",
        "        (pl.col(\"miniRules1_monetaryAmount\") == 0)\n",
        "        & (pl.col(\"miniRules1_statusInfos\") == 1)\n",
        "    )\n",
        "    .cast(pl.Int8)\n",
        "    .alias('free_exchange'),\n",
        "\n",
        "    # Routes and carriers\n",
        "    pl.col('searchRoute').is_in([\"MOWLED/LEDMOW\", \"LEDMOW/MOWLED\", \"MOWLED\", \"LEDMOW\"]).cast(pl.Int32).alias(\"is_popular_route\"),\n",
        "\n",
        "    # Cabin\n",
        "    pl.mean_horizontal(['legs0_segments0_cabinClass', 'legs1_segments0_cabinClass']).alias('avg_cabin_class'),\n",
        "    (pl.col('legs0_segments0_cabinClass').fill_null(0) - pl.col('legs1_segments0_cabinClass').fill_null(0)).alias('cabin_diff'),\n",
        "])"
      ],
      "metadata": {
        "id": "wj0sbfpbCxz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segment counts - more efficient\n",
        "seg_exprs = []\n",
        "for leg in (0, 1):\n",
        "  seg_cols = [f\"legs{leg}_segments{s}_duration\" for s in range(4) if f\"legs{leg}_segments{s}_duration\" in df.columns]\n",
        "  if seg_cols:\n",
        "    seg_exprs.append(\n",
        "        pl.sum_horizontal(pl.col(c).is_not_null() for c in seg_cols)\n",
        "        .cast(pl.Int32).alias(f\"n_segments_leg{leg}\")\n",
        "    )\n",
        "  else:\n",
        "    seg_exprs.append(pl.lit(0).cast(pl.Int32).alias(f\"n_segments_leg{leg}\"))\n",
        "\n",
        "# Add segment-based features\n",
        "# First create segment counts\n",
        "df = df.with_columns(seg_exprs)\n",
        "\n",
        "# Then use them for derived features\n",
        "df = df.with_columns([\n",
        "    (pl.col(\"n_segments_leg0\") + pl.col(\"n_segments_leg1\")).alias(\"total_segments\"),\n",
        "    (pl.col(\"n_segments_leg0\") == 1).cast(pl.Int32).alias(\"is_direct_leg0\"),\n",
        "    pl.when(pl.col(\"is_one_way\") == 1).then(0).otherwise((pl.col(\"n_segments_leg1\") == 1)).cast(pl.Int32).alias('is_direct_leg1')\n",
        "])\n",
        "\n",
        "# More derived features\n",
        "df = df.with_columns([\n",
        "    (pl.col(\"is_direct_leg0\") & pl.col(\"is_direct_leg1\")).cast(pl.Int32).alias('both_direct'),\n",
        "    ((pl.col(\"isVip\") == 1) | (pl.col(\"n_ff_programs\") > 0)).cast(pl.Int32).alias('is_vip_freq'),\n",
        "    (pl.col(\"total_baggage\") > 0).cast(pl.Int32).alias('has_baggage'),\n",
        "    (pl.col('total_fees') > 0).cast(pl.Int32).alias('has_fees'),\n",
        "    (pl.col(\"total_fees\") / (pl.col('totalPrice') + 1)).alias('fee_rate'),\n",
        "    pl.col('Id').count().over('ranker_id').alias('group_size'),\n",
        "])\n",
        "\n",
        "# Add major carrier flag if column exists\n",
        "if \"legs0_segments0_marketingCarrier_code\" in df.columns:\n",
        "  df = df.with_columns(\n",
        "      pl.col(\"legs0_segments0_marketingCarrier_code\").is_in([\"SU\", \"S7\"]).cast(pl.Int32).alias(\"is_major_carrier\")\n",
        "  )\n",
        "else:\n",
        "  df = df.with_columns(pl.lit(0).cast(pl.Int32).alias(\"is_major_carrier\"))\n",
        "\n",
        "df = df.with_columns(pl.col('group_size').log1p().alias('group_size_log'))\n",
        "\n",
        "# Time features - batch process\n",
        "time_exprs = []\n",
        "for col in (\"legs0_departureAt\", \"legs0_arrivalAt\", \"legs1_departureAt\", \"legs1_arrivalAt\"):\n",
        "  if col in df.columns:\n",
        "    dt = pl.col(col).str.to_datetime(strict=False)\n",
        "    h = dt.dt.hour().fill_null(12)\n",
        "    time_exprs.extend([\n",
        "        h.alias(f\"{col}_hour\"),\n",
        "        dt.dt.weekday().fill_null(0).alias(f\"{col}_weekday\"),\n",
        "        (((h >= 6) & (h <= 9)) | ((h >= 17) & (h <= 20))).cast(pl.Int32).alias(f\"{col}_business_time\")\n",
        "    ])\n",
        "\n",
        "if time_exprs:\n",
        "  df = df.with_columns(time_exprs)\n",
        "\n",
        "# Batch rank computations - more efficient with single pass\n",
        "# First apply the columns that will be used for ranking\n",
        "df = df.with_columns([\n",
        "    pl.col('group_size').log1p().alias('group_size_log'),\n",
        "])\n",
        "\n",
        "# Price and duration basic ranks\n",
        "rank_exprs = []\n",
        "for col, alias in [('totalPrice', 'price'), ('total_duration', 'duration')]:\n",
        "  rank_exprs.append(\n",
        "      pl.col(col).rank().over('ranker_id').alias(f\"{alias}_rank\")\n",
        "  )\n",
        "\n",
        "# Price-specific features\n",
        "price_exprs = [\n",
        "    (pl.col(\"totalPrice\").rank(\"average\").over(\"ranker_id\") /\n",
        "     pl.col(\"totalPrice\").count().over(\"ranker_id\")).alias(\"price_pct_rank\"),\n",
        "\n",
        "    (pl.col(\"totalPrice\") == pl.col(\"totalPrice\").min().over(\"ranker_id\")).cast(pl.Int32).alias(\"is_cheapest\"),\n",
        "\n",
        "    ((pl.col('totalPrice') - pl.col('totalPrice').median().over('ranker_id')) /\n",
        "     (pl.col('totalPrice').std().over('ranker_id') + 1)).alias('price_from_median'),\n",
        "\n",
        "    (pl.col(\"l0_seg\") == pl.col(\"l0_seg\").min().over(\"ranker_id\")).cast(pl.Int32).alias(\"is_min_segments\"),\n",
        "]\n",
        "\n",
        "# Apply initial ranks\n",
        "df = df.with_columns(rank_exprs + price_exprs)\n",
        "\n",
        "# Cheapest direct - more efficient\n",
        "direct_cheapest = (\n",
        "    df.filter(pl.col('is_direct_leg0') == 1)\n",
        "    .group_by('ranker_id')\n",
        "    .agg(pl.col('totalPrice').min().alias('min_direct'))\n",
        ")\n",
        "\n",
        "df = df.join(direct_cheapest, on='ranker_id', how='left').with_columns(\n",
        "    ((pl.col('is_direct_leg0') == 1) &\n",
        "     (pl.col('totalPrice') == pl.col('min_direct'))).cast(pl.Int32).fill_null(0).alias('is_cheapest_direct')\n",
        ").drop('min_direct')\n",
        "\n",
        "# Popularity features - efficient join\n",
        "df = (\n",
        "    df.join(\n",
        "        train.group_by('legs0_segments0_marketingCarrier_code').agg(pl.mean('selected').alias('carrier0_pop')),\n",
        "        on='legs0_segments0_marketingCarrier_code',\n",
        "        how='left'\n",
        "    )\n",
        "    .join(\n",
        "        train.group_by('legs1_segments0_marketingCarrier_code').agg(pl.mean('selected').alias('carrier1_pop')),\n",
        "        on='legs1_segments0_marketingCarrier_code',\n",
        "        how='left'\n",
        "    )\n",
        "    .with_columns([\n",
        "        pl.col('carrier0_pop').fill_null(0.0),\n",
        "        pl.col('carrier1_pop').fill_null(0.0),\n",
        "    ])\n",
        ")\n",
        "\n",
        "# Final features including popularity\n",
        "df = df.with_columns([\n",
        "    (pl.col('carrier0_pop') * pl.col('carrier1_pop')).alias(\"carrier_pop_product\"),\n",
        "])"
      ],
      "metadata": {
        "id": "hJ5wO9bCjEcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill nulls\n",
        "data = df.with_columns(\n",
        "    [pl.col(c).fill_null(0) for c in df.select(pl.selectors.numeric()).columns] +\n",
        "    [pl.col(c).fill_null(\"missing\") for c in df.select(pl.selectors.string()).columns]\n",
        ")"
      ],
      "metadata": {
        "id": "FRDn8LDHjEtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "x-nbNDiN8Nnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Selection**"
      ],
      "metadata": {
        "id": "wla5zVZVWVES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical Features\n",
        "cat_features = [\n",
        "    \"nationality\", \"searchRoute\", \"corporateTariffCode\",\n",
        "    \"bySelf\", \"sex\", \"companyID\",\n",
        "\n",
        "    # Leg 0 segments 0-1\n",
        "    \"legs0_segments0_aircraft_code\", \"legs0_segments0_arrivalTo_airport_city_iata\",\n",
        "    \"legs0_segments0_arrivalTo_airport_iata\", \"legs0_segments0_departureFrom_airport_city_iata\",\n",
        "    \"legs0_segments0_departureFrom_airport_iata\", 'legs0_segments0_duration'\n",
        "    \"legs0_segments0_marketingCarrier_code\", \"legs0_segments0_operatingCarrier_code\",\n",
        "    \"legs0_segments0_flightNumber\",\n",
        "    \"legs0_segments1_aircraft_code\", \"legs0_segments1_arrivalTo_airport_city_iata\",\n",
        "    \"legs0_segments1_arrivalTo_airport_iata\", \"legs0_segments1_departureFrom_airport_city_iata\",\n",
        "    'legs0_segments1_duration',\n",
        "    \"legs0_segments1_marketingCarrier_code\", \"legs0_segments1_operatingCarrier_code\",\n",
        "    \"legs0_segments1_flightNumber\",\n",
        "\n",
        "    # Leg 1 segments 0-1\n",
        "    \"legs1_segments0_aircraft_code\", \"legs1_segments0_arrivalTo_airport_city_iata\",\n",
        "    \"legs1_segments0_arrivalTo_airport_iata\", \"legs1_segments0_departureFrom_airport_city_iata\",\n",
        "    \"legs1_segments0_departureFrom_airport_iata\", 'legs1_segments0_duration'\n",
        "    \"legs1_segments0_marketingCarrier_code\", \"legs1_segments0_operatingCarrier_code\",\n",
        "    \"legs1_segments0_flightNumber\",\n",
        "    \"legs1_segments1_aircraft_code\", \"legs1_segments1_arrivalTo_airport_city_iata\",\n",
        "    \"legs1_segments1_arrivalTo_airport_iata\", \"legs1_segments1_departureFrom_airport_city_iata\",\n",
        "    'legs1_segments1_duration',\n",
        "    \"legs1_segments1_marketingCarrier_code\", \"legs1_segments1_operatingCarrier_code\",\n",
        "    \"legs1_segments1_flightNumber\",\n",
        "]\n",
        "\n",
        "# Columns to exclude (uninformative and problematic)\n",
        "exclude_cols = [\n",
        "    \"Id\", \"ranker_id\", \"selected\", \"profileId\", \"requestDate\",\n",
        "    \"legs0_departureAt\", \"legs0_arrivalAt\", \"legs1_departureAt\", \"legs1_arrivalAt\",\n",
        "    \"miniRules0_percentage\", \"miniRules1_percentage\",  # > 90% missing\n",
        "    \"frequentFlyer\", # Already processed\n",
        "    # Exclude constant columns\n",
        "    \"pricingInfo_passengerCount\"\n",
        "]\n",
        "\n",
        "for leg in [0, 1]:\n",
        "  for seg in [0, 1]:\n",
        "    if seg == 0:\n",
        "      suffixes =[\n",
        "          \"seatsAvailable\",\n",
        "      ]\n",
        "    else:\n",
        "      suffixes = [\n",
        "          \"cabinClass\",\n",
        "          \"seatsAvailable\",\n",
        "          \"baggageAllowance_quantity\",\n",
        "          \"baggageAllowance_weightMeasurementType\",\n",
        "          \"aircraft_code\",\n",
        "          \"arrivalTo_airport_city_iata\",\n",
        "          \"arrivalTo_airport_iata\",\n",
        "          \"departureFrom_airport_iata\",\n",
        "          \"flightNumber\",\n",
        "          \"marketingCarrier_code\",\n",
        "          \"operatingCarrier_code\",\n",
        "      ]\n",
        "    for suffix in suffixes:\n",
        "      exclude_cols.append(f\"legs{leg}_segments{seg}_{suffix}\")\n",
        "\n",
        "# Exclude segment 2-3 columns (> 98% missing)\n",
        "for leg in [0, 1]:\n",
        "  for seg in [2, 3]:\n",
        "    for suffix in [\"aircraft_code\", \"arrivalTo_airport_city_iata\", \"arrivalTo_airport_iata\",\n",
        "                   \"baggageAllowance_quantity\", \"baggageAllowance_weightMeasurementType\",\n",
        "                   \"cabinClass\", \"departureFrom_airport_iata\", \"duration\", \"flightNumber\",\n",
        "                   \"marketingCarrier_code\", \"operatingCarrier_code\",\n",
        "                   \"seatsAvailable\"]:\n",
        "                   exclude_cols.append(f\"legs{leg}_segments{seg}_{suffix}\")\n",
        "\n",
        "feature_cols = [col for col in data.columns if col not in exclude_cols]\n",
        "cat_features_final = [col for col in cat_features if col in feature_cols]\n",
        "\n",
        "print(f\"Using {len(feature_cols)} features ({len(cat_features_final)} categorical)\")\n",
        "\n",
        "X = data.select(feature_cols)\n",
        "y = data.select(\"selected\")\n",
        "groups = data.select(\"ranker_id\")"
      ],
      "metadata": {
        "id": "3dTkEOrWjE7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Training**"
      ],
      "metadata": {
        "id": "iE_g1GBvXJUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_xgb = X.with_columns([(pl.col(c).rank(\"dense\") - 1).fill_null(-1).cast(pl.Int16) for c in cat_features_final])"
      ],
      "metadata": {
        "id": "0oG5K-9zLlQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_xgb.schema"
      ],
      "metadata": {
        "id": "byp1WEX9_BkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string_cols = [col for col, dtype in data_xgb.schema.items() if \"String\" in str(dtype)]\n",
        "print(string_cols)"
      ],
      "metadata": {
        "id": "QaX6XFXxLavA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in string_cols:\n",
        "  data_xgb = data_xgb.with_columns(pl.col(c).fill_null(\"unknown\").cast(pl.Categorical).cast(pl.Int32))\n"
      ],
      "metadata": {
        "id": "kZIMUPnWCesP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_xgb.schema"
      ],
      "metadata": {
        "id": "5bGo9WwGCwRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n1 = 16487352 # Split train to train and val (10%) in time\n",
        "n2 = train.height\n",
        "data_xgb_train, data_xgb_val, data_xgb_test = data_xgb[:n2], data_xgb[n1:n2], data_xgb[n2:]\n",
        "y_train, y_val, y_test = y[:n2], y[n1:n2], y[n2:]\n",
        "group_train, group_val, group_test = groups[:n2], groups[n1:n2], groups[n2:]\n",
        "\n",
        "group_sizes_train = group_train.group_by('ranker_id', maintain_order=True).agg(pl.len())['len'].to_numpy()\n",
        "group_sizes_val = group_val.group_by('ranker_id', maintain_order=True).agg(pl.len())['len'].to_numpy()\n",
        "group_sizes_test = group_test.group_by('ranker_id', maintain_order=True).agg(pl.len())['len'].to_numpy()\n",
        "\n",
        "dtrain = xgb.DMatrix(data_xgb_train, label=y_train, group=group_sizes_train, feature_names=data_xgb.columns)\n",
        "dval = xgb.DMatrix(data_xgb_val, label=y_val, group=group_sizes_val, feature_names=data_xgb.columns)\n",
        "dtest = xgb.DMatrix(data_xgb_test, label=y_test, group=group_sizes_test, feature_names=data_xgb.columns)"
      ],
      "metadata": {
        "id": "4QQhWzhdjFO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost parameters\n",
        "xgb_params = {\n",
        "    'objective':'rank:pairwise',\n",
        "    'eval_metric': 'ndcg@3',\n",
        "    'learning_rate': 0.022641389657079056,\n",
        "    'max_depth': 14,\n",
        "    'min_child_weight': 2,\n",
        "    'subsample': 0.8842234913702768,\n",
        "    'colsample_bytree':  0.45840689146263086,\n",
        "    \"gamma\": 3.3084297630544888,\n",
        "    \"lambda\": 6.952586917313028,\n",
        "    \"alpha\": 0.6395254133055179,\n",
        "    'seed': RANDOM_STATE,\n",
        "    'n_jobs': -1,\n",
        "    # 'device': 'cuda'\n",
        "}\n",
        "\n",
        "# Train XGBoost model\n",
        "print('Training XGBoost model...')\n",
        "xgb_model = xgb.train(\n",
        "    xgb_params,\n",
        "    dtrain,\n",
        "    num_boost_round = 800,\n",
        "    evals = [(dtrain, 'train'), (dval, 'val')],\n",
        "    verbose_eval = 50,\n",
        "    #early_stopping_rounds = 100\n",
        ")"
      ],
      "metadata": {
        "id": "mOVAFbewBvXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate XGBoost\n",
        "xgb_val_preds = xgb_model.predict(dval)\n",
        "xgb_hr3 = hitrate_at_3(y_val, xgb_val_preds, group_val)\n",
        "print(f\"HiRate@3: {xgb_hr3:.3f}\")"
      ],
      "metadata": {
        "id": "aIF5Bm20Bvrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_importance = xgb_model.get_score(importance_type='gain')\n",
        "xgb_importance_df = pl.DataFrame(\n",
        "    [{'features':k, 'importance':v} for k, v in xgb_importance.items()]\n",
        ").sort('importance', descending=bool(1))\n",
        "print(xgb_importance_df.head(20).to_pandas().to_string())"
      ],
      "metadata": {
        "id": "vJvBjySeBvuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Submission**"
      ],
      "metadata": {
        "id": "azocmdA0EPni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing a **re-ranking strategy** for XGBoost predictions in a **learning-to-rank** or **search result reranking** task - likely in a competition or production setting for flight search ranking."
      ],
      "metadata": {
        "id": "O2Fdgr5GTCKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def re_rank(test: pl.DataFrame, submission_xgb: pl.DataFrame, penalty_factor=0.1):\n",
        "  # This function tries to adjust the ranking to reduce duplicates of the same flight in top positions\n",
        "  COlS_TO_COMPARE = [\n",
        "      \"legs0_departureAt\",\n",
        "      \"legs0_arrivalAt\",\n",
        "      \"legs1_departureAt\",\n",
        "      \"legs1_arrivalAt\",\n",
        "      \"legs0_segments0_flightNumber\",\n",
        "      \"legs1_segments0_flightNumber\",\n",
        "      \"legs0_segments0_aircraft_code\",\n",
        "      \"legs1_segments0_aircraft_code\",\n",
        "      \"legs0_segments0_departureFrom_airport_iata\",\n",
        "      \"legs1_segments0_departureFrom_airport_iata\",\n",
        "  ]\n",
        "  # Preprocess comparison columns\n",
        "  test = test.with_columns(\n",
        "      [pl.col(c).cast(str).fill_null(\"NULL\") for c in COlS_TO_COMPARE]\n",
        "  ) # Ensures flight info is all string and filled for safe concatenation.\n",
        "\n",
        "  # Join predictions with test data\n",
        "  df =  submission_xgb.join(test, on=['Id', 'ranker_id'], how='left')\n",
        "\n",
        "  # Create `flight_hash`: This groups flights with same route + aircraft + flight number, i.e., same physical flight.\n",
        "  df = df.with_columns(\n",
        "      (\n",
        "          pl.col(\"legs0_departureAt\")\n",
        "          + '_'\n",
        "          + pl.col('legs0_arrivalAt')\n",
        "          + '_'\n",
        "          + pl.col(\"legs1_departureAt\")\n",
        "          + '_'\n",
        "          + pl.col('legs1_arrivalAt')\n",
        "          + '_'\n",
        "          + pl.col('legs0_segments0_flightNumber')\n",
        "          + '_'\n",
        "          + pl.col('legs1_segments0_flightNumber')\n",
        "      ).alias(\"flight_hash\")\n",
        "  )\n",
        "\n",
        "  # Get max score within same flight group: This find best prediction score for each duplicate flight group\n",
        "  df = df.with_columns(\n",
        "      pl.max('pred_score')\n",
        "      .over(['ranker_id', \"flight_hash\"])\n",
        "      .alias('max_score_same_flight')\n",
        "  )\n",
        "\n",
        "  # Penalize duplicates: Penalize predictions based on distance from the best duplicate:\n",
        "  ## If it's already the best -> no penalty\n",
        "  ## If it's a worse duplicate -> penalized\n",
        "  df = df.with_columns(\n",
        "      (\n",
        "          pl.col('pred_score') - penalty_factor * (pl.col('max_score_same_flight') - pl.col('pred_score'))\n",
        "      ).alias('reorder_score')\n",
        "  )\n",
        "\n",
        "  # Re-rannk using penalize score\n",
        "  df = df.with_columns(\n",
        "      pl.col('reorder_score')\n",
        "      .rank(method='ordinal', descending=True)\n",
        "      .over('ranker_id')\n",
        "      .cast(pl.Int32)\n",
        "      .alias('new_selected')\n",
        "  )\n",
        "\n",
        "  return df.select(['Id', 'ranker_id', 'new_selected', 'pred_score', 'reorder_score'])\n",
        "\n",
        "submission_xgb = (\n",
        "    test.select(['Id', 'ranker_id'])\n",
        "    .with_columns(pl.Series('pred_score', xgb_model.predict(dtest)))\n",
        "    .with_columns(\n",
        "        [\n",
        "            pl.col('pred_score')\n",
        "            .rank(method='ordinal', descending=True)\n",
        "            .over('ranker_id')\n",
        "            .cast(pl.Int32)\n",
        "            .alias('selected')\n",
        "        ]\n",
        "    )\n",
        "    .select(['Id', 'ranker_id', 'selected', 'pred_score'])\n",
        ")\n",
        "\n",
        "top = re_rank(test, submission_xgb)\n",
        "\n",
        "# Merge and finalize new ranking\n",
        "submission_xgb = (\n",
        "    submission_xgb.join(top, on=['Id', 'ranker_id'], how='left')\n",
        "    .with_columns(\n",
        "        [\n",
        "            pl.when(pl.col('new_selected').is_not_null())\n",
        "            .then(pl.col('new_selected'))\n",
        "            .otherwise(pl.col('selected'))\n",
        "            .alias('selected')\n",
        "        ]\n",
        "    )\n",
        "    .select(['Id', 'ranker_id', 'selected'])\n",
        ")\n",
        "\n",
        "# Create the final submission\n",
        "submission_xgb.write_csv('submission.csv')"
      ],
      "metadata": {
        "id": "yuAf66UQBvyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why using this re-ranking strategy?**\n",
        "To **avoid redundant or identical results appearing at the top** of ranked predictions. For example:\n",
        "> If multiple identical flights (same time, flight number, etc.) exist , only the best should at the top - others are penalized and pushed down."
      ],
      "metadata": {
        "id": "qA6EIq0zb-yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_xgb.head(20)"
      ],
      "metadata": {
        "id": "rJe1maqKj7DP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}